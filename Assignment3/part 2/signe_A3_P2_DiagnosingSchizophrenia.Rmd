---
title: "Assignment 3 - Part 2 - Diagnosing Schizophrenia from Voice"
author: "Riccardo Fusaroli"
date: "October 17, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Assignment 3 - Diagnosing schizophrenia from voice

In the previous part of the assignment you generated a bunch of "features", that is, of quantitative descriptors of voice in schizophrenia, focusing on pitch.
In the course of this assignment we will use them to try to automatically diagnose schizophrenia from voice only, that is, relying on the set of features you produced last time, we will try to produce an automated classifier.

### Question 1: Can you diagnose schizophrenia from pitch range only? If so, how well?

Build a logistic regression to see whether you can diagnose schizophrenia from pitch range only.

Calculate the different performance measures (accuracy, sensitivity, specificity, PPV, NPV, ROC curve) on a logistic regression using the full dataset. Don't forget the random effects!

Then cross-validate the logistic regression and re-calculate performance on the testing folds. N.B. The cross-validation functions you already have should be t cdsaasfweaked: you need to calculate these new performance measures.

N.B. the predict() function generates log odds (the full scale between minus and plus infinity). Log odds > 0 indicates a choice of 1, below a choice of 0.
N.B. you need to decide whether calculate performance on each single test fold or save all the prediction for test folds in one datase, so to calculate overall performance.
N.B. Now you have two levels of structure: subject and study. Should this impact your cross-validation?


```{r}
library(tidyverse)
library(ggplot2)
library(lme4)
library(dplyr)
library(MuMIn)
library(effects)
library(Metrics)
library(caret)
library(simr)
library(lmerTest)
library(stringr)
library(purrr)
library(FinCal)
library(boot)
library(pROC)


schi_data <- read.csv("schizoAcousticData.csv")

#need to convert subject back so minus 100, to make them paired again
schi_data$Subject <- ifelse(schi_data$Diagnosis == 0, schi_data$Subject-1000, schi_data$Subject)



#rescale variables into z-scores 

schi_data$z.qr95 = scale(schi_data$qr95, center = TRUE, scale = TRUE) #center: if TRUE, the objects’ column means are subtracted from the values in those columns (ignoring NAs), scale: if TRUE, the centered column values are divided by the column’s standard deviation

schi_data$z.Mean = scale(schi_data$Mean, center = TRUE, scale = TRUE)
schi_data$z.sd = scale(schi_data$sd, center = TRUE, scale = TRUE)
schi_data$z.q05 = scale(schi_data$q05, center = TRUE, scale = TRUE)
schi_data$z.q25 = scale(schi_data$q25, center = TRUE, scale = TRUE)
schi_data$z.q50 = scale(schi_data$q50, center = TRUE, scale = TRUE)
schi_data$z.q75 = scale(schi_data$q75, center = TRUE, scale = TRUE)
schi_data$z.q95 = scale(schi_data$q95, center = TRUE, scale = TRUE)
schi_data$z.qr75 = scale(schi_data$qr75, center = TRUE, scale = TRUE)
schi_data$z.MAD = scale(schi_data$MAD, center = TRUE, scale = TRUE)
schi_data$z.CoefVar = scale(schi_data$CoefVar, center = TRUE, scale = TRUE)

#rescale variables with either min/max or z-scales 
#an assumption when making the models is that the continious models are on a somewhat similar scale, so if one variable is on a scale from 0 to 1000 and another variable on a scale from 1 to 3

#z-scale - substract the mean and divide by the standard deviation


#important to convert it back when you want to interpret it 

features = colnames(schi_data)[6:16] #create list with feature names
zfeatures = c(colnames(schi_data)[30:40]) #create list with z feature names 


```


```{r}

#model from pitch range only
qr95_model <- glmer(Diagnosis ~ z.qr95 + Gender + (1| Subject) + (1| Triangle), schi_data, family = "binomial")

#lets plot the data
ggplot(schi_data, aes(z.qr95,Diagnosis,colour=Diagnosis)) + geom_point() + theme_classic()

#does not really look like it's a good predictor 
```


```{r}
#if p is the probability of an event, the odds of the event are then p/(1 − p)

#predict to test accuracy
schi_data$logodds_qr95 <- predict(qr95_model, schi_data, allow.new.levels = TRUE) #they are in log odds


#to get probabilities from the log odds we take the inverse logit of them
schi_data$prob_qr95 <- inv.logit(schi_data$logodds_qr95)



#create ruc curve
rocCurve <- roc(response = schi_data$Diagnosis, predictor = as.numeric(schi_data$prob_qr95))

#area under the curve
auc(rocCurve)

#95% confidence interval
ci(rocCurve)

#lets plot it
plot(rocCurve, legacy.axes = TRUE)


#use decision rule
schi_data$prob_qr95[schi_data$prob_qr95 > 0.5 ] = 1
schi_data$prob_qr95[schi_data$prob_qr95 <= 0.5 ] = 0

#make sure it's in factors
schi_data$prob_qr95 <- as.factor(schi_data$prob_qr95)
schi_data$Diagnosis <- as.factor(schi_data$Diagnosis)

#make a confusion matrix to get performance measures
confusionMatrix(schi_data$prob_qr95, reference = schi_data$Diagnosis, positive = "1")



```
```{r}
#cross validation 

#schi_data$Subject <- as.numeric(schi_data$Subject)

folds <- createFolds(unique(schi_data$Subject), k=5, list = TRUE, returnTrain = FALSE) #create folds. Unique() puts each unique person in a fold, so all data from one subject goes into one fold

folds <-lapply(folds, function(x) unique(schi_data$Subject)[x])

folds



#change zfeatures to nummeric
zfea <- 30:40
schi_data[zfea] <- lapply(schi_data[zfea], as.numeric)


#schi_data$Subject <- as.numeric(as.factor(schi_data$Subject))

qr95_pred = rep(NA, nrow(schi_data))


for (f in folds) {
  #divide into test and train
  temp_test = filter(schi_data, Subject %in% f) #could also have used train_data[f,]
  temp_train = filter(schi_data, ! Subject %in% f) #could also have used train_data[!f,]
  
  #run model on training data
  qr95_model <- glmer(Diagnosis ~ z.qr95 + (1| Subject) + (1| Triangle), temp_train, family = "binomial")
  
  #predict and get in probabilities 
  temp_test$qr95_predictions = inv.logit(predict(qr95_model, temp_test, allow.new.levels = TRUE))
  
  #want to save all predictions 
  qr95_pred[schi_data$Subject %in% f] = temp_test$qr95_predictions

  }


#create ruc curve
rocCurve <- roc(response = schi_data$Diagnosis, predictor = qr95_pred)

#area under the curve
auc(rocCurve)

#95% confidence interval
ci(rocCurve)

#lets plot it
plot(rocCurve, legacy.axes = TRUE)


#can add the predictions to the dataframe
schi_data$qr95_pred <- qr95_pred 

#use decision rules, if more than fifty percent diagnose as schizofrenic, if less diagnose as control
schi_data$qr95_pred[schi_data$qr95_pred > 0.5] = 1
schi_data$qr95_pred[schi_data$qr95_pred <= 0.5] = 0



#make a confusion matrix to get performance measures
confusionMatrix(as.factor(schi_data$qr95_pred), reference = as.factor(schi_data$Diagnosis))


```



### Question 2 - Which single acoustic predictor is the best predictor of diagnosis?


```{r}
#cross validation 
#use lapply function, 

folds <- createFolds(unique(schi_data$Subject), k=5, list = TRUE, returnTrain = FALSE) #create folds. Unique() puts each unique person in a fold, so all data from one subject goes into one fold

folds <-lapply(folds, function(x) unique(schi_data$Subject)[x])

folds

qr95_pred = rep(NA, nrow(schi_data))
qr75_pred = rep(NA, nrow(schi_data))
q05_pred = rep(NA, nrow(schi_data))
q25_pred = rep(NA, nrow(schi_data))
q50_pred = rep(NA, nrow(schi_data))
q75_pred = rep(NA, nrow(schi_data))
q95_pred = rep(NA, nrow(schi_data))
Mean_pred = rep(NA, nrow(schi_data))
sd_pred = rep(NA, nrow(schi_data))
CoefVar_pred = rep(NA, nrow(schi_data))
MAD_pred = rep(NA, nrow(schi_data))


for (f in folds) {
  #divide into test and train
  temp_test = filter(schi_data, Subject %in% f) #could also have used train_data[f,]
  temp_train = filter(schi_data, ! Subject %in% f) #could also have used train_data[!f,]
  
  #run model on training data
  qr95_model <- glmer(Diagnosis ~ z.qr95  + (1| Subject) + (1| Triangle), temp_train, family = "binomial")
  q05_model <- glmer(Diagnosis ~ z.q05  + (1| Subject) + (1| Triangle), temp_train, family = "binomial")
  q25_model <- glmer(Diagnosis ~ z.q25  + (1| Subject) + (1| Triangle), temp_train, family = "binomial")
  q50_model <- glmer(Diagnosis ~ z.q50  + (1| Subject) + (1| Triangle), temp_train, family = "binomial")
  q75_model <- glmer(Diagnosis ~ z.q75  + (1| Subject) + (1| Triangle), temp_train, family = "binomial")
  q95_model <- glmer(Diagnosis ~ z.q95  + (1| Subject) + (1| Triangle), temp_train, family = "binomial")
  qr75_model <- glmer(Diagnosis ~ z.qr75  + (1| Subject) + (1| Triangle), temp_train, family = "binomial")
  Mean_model <- glmer(Diagnosis ~ z.Mean  + (1| Subject) + (1| Triangle), temp_train, family = "binomial")
  sd_model <- glmer(Diagnosis ~ z.sd  + (1| Subject) + (1| Triangle), temp_train, family = "binomial")
  CoefVar_model <- glmer(Diagnosis ~ z.CoefVar  + (1| Subject) + (1| Triangle), temp_train, family = "binomial")
  MAD_model <- glmer(Diagnosis ~ z.MAD  + (1| Subject) + (1| Triangle), temp_train, family = "binomial")
  
  
  #predict and get in probabilities 
  temp_test$qr95_predictions = inv.logit(predict(qr95_model, temp_test, allow.new.levels = TRUE))
  temp_test$qr75_predictions = inv.logit(predict(qr75_model, temp_test, allow.new.levels = TRUE))
  temp_test$q05_predictions = inv.logit(predict(q05_model, temp_test, allow.new.levels = TRUE))
  temp_test$q25_predictions = inv.logit(predict(q25_model, temp_test, allow.new.levels = TRUE))
  temp_test$q50_predictions = inv.logit(predict(q50_model, temp_test, allow.new.levels = TRUE))
  temp_test$q75_predictions = inv.logit(predict(q75_model, temp_test, allow.new.levels = TRUE))
  temp_test$q95_predictions = inv.logit(predict(q95_model, temp_test, allow.new.levels = TRUE))
  temp_test$Mean_predictions = inv.logit(predict(Mean_model, temp_test, allow.new.levels = TRUE))
  temp_test$sd_predictions = inv.logit(predict(sd_model, temp_test, allow.new.levels = TRUE))
  temp_test$CoefVar_predictions = inv.logit(predict(CoefVar_model, temp_test, allow.new.levels = TRUE))
  temp_test$MAD_predictions = inv.logit(predict(MAD_model, temp_test, allow.new.levels = TRUE))
  
  #want to save all predictions 
  qr95_pred[schi_data$Subject %in% f] = temp_test$qr95_predictions
  qr75_pred[schi_data$Subject %in% f] = temp_test$qr75_predictions
  q05_pred[schi_data$Subject %in% f] = temp_test$q05_predictions
  q25_pred[schi_data$Subject %in% f] = temp_test$q25_predictions
  q50_pred[schi_data$Subject %in% f] = temp_test$q50_predictions
  q75_pred[schi_data$Subject %in% f] = temp_test$q75_predictions
  q95_pred[schi_data$Subject %in% f] = temp_test$q95_predictions
  Mean_pred[schi_data$Subject %in% f] = temp_test$Mean_predictions
  sd_pred[schi_data$Subject %in% f] = temp_test$sd_predictions
  CoefVar_pred[schi_data$Subject %in% f] = temp_test$CoefVar_predictions
  MAD_pred[schi_data$Subject %in% f] = temp_test$MAD_predictions

  
  }

#use decision rules, if more than fifty percent diagnose as schizofrenic, if less diagnose as control
qr95_pred[qr95_pred > 0.5] = 1
qr95_pred[qr95_pred <= 0.5] = 0

qr75_pred[qr75_pred > 0.5] = 1
qr75_pred[qr75_pred <= 0.5] = 0

q05_pred[q05_pred > 0.5] = 1
q05_pred[q05_pred <= 0.5] = 0

q25_pred[q25_pred > 0.5] = 1
q25_pred[q25_pred <= 0.5] = 0

q50_pred[q50_pred > 0.5] = 1
q50_pred[q50_pred <= 0.5] = 0

q75_pred[q75_pred > 0.5] = 1
q75_pred[q75_pred <= 0.5] = 0

q95_pred[q95_pred > 0.5] = 1
q95_pred[q95_pred <= 0.5] = 0

Mean_pred[Mean_pred > 0.5] = 1
Mean_pred[Mean_pred <= 0.5] = 0

sd_pred[sd_pred > 0.5] = 1
sd_pred[sd_pred <= 0.5] = 0

CoefVar_pred[CoefVar_pred > 0.5] = 1
CoefVar_pred[CoefVar_pred <= 0.5] = 0

MAD_pred[MAD_pred > 0.5] = 1
MAD_pred[MAD_pred <= 0.5] = 0

  

#make a confusion matrix to get performance measures
print(paste("qr95 has an accuracy of: ", round(confusionMatrix(as.factor(qr95_pred), reference = as.factor(schi_data$Diagnosis))$overall[1], 3)))

print(paste("qr75 has an accuracy of: ", round(confusionMatrix(as.factor(qr75_pred), reference = as.factor(schi_data$Diagnosis))$overall[1], 3)))

print(paste("q05 has an accuracy of: ", round(confusionMatrix(as.factor(q05_pred), reference = as.factor(schi_data$Diagnosis))$overall[1], 3)))

print(paste("q25 has an accuracy of: ", round(confusionMatrix(as.factor(q25_pred), reference = as.factor(schi_data$Diagnosis))$overall[1], 3)))

print(paste("q50 has an accuracy of: ", round(confusionMatrix(as.factor(q50_pred), reference = as.factor(schi_data$Diagnosis))$overall[1], 3)))

print(paste("q75 has an accuracy of: ", round(confusionMatrix(as.factor(q75_pred), reference = as.factor(schi_data$Diagnosis))$overall[1], 3)))

print(paste("q95 has an accuracy of: ", round(confusionMatrix(as.factor(q95_pred), reference = as.factor(schi_data$Diagnosis))$overall[1], 3)))


print(paste("Mean has an accuracy of: ", round(confusionMatrix(as.factor(Mean_pred), reference = as.factor(schi_data$Diagnosis))$overall[1], 3)))

print(paste("sd has an accuracy of: ", round(confusionMatrix(as.factor(sd_pred), reference = as.factor(schi_data$Diagnosis))$overall[1], 3)))

print(paste("CoefVar has an accuracy of: ", round(confusionMatrix(as.factor(CoefVar_pred), reference = as.factor(schi_data$Diagnosis))$overall[1], 3)))

print(paste("MAD has an accuracy of: ", round(confusionMatrix(as.factor(MAD_pred), reference = as.factor(schi_data$Diagnosis))$overall[1], 3)))



```


### Question 3 - Which combination of acoustic predictors is best for diagnosing schizophrenia?

Now it's time to go wild! Use all (voice-related) variables and interactions you can think of. Compare models and select the best performing model you can find.

Remember:
- Out-of-sample error crucial to build the best model!
- After choosing the model, send Malte and Riccardo the code of your model


How do we compare the models? 
- 

### Question 4: Properly report the results

METHODS SECTION: how did you analyse the data? That is, how did you extract the data, designed the models and compared their performance?

RESULTS SECTION: can you diagnose schizophrenia based on voice? which features are used? Comment on the difference between the different performance measures.

### Bonus question 5

You have some additional bonus data involving speech rate, pauses, etc. Include them in your analysis. Do they improve classification?

### Bonus question 6

Logistic regression is only one of many classification algorithms. Try using others and compare performance. Some examples: Discriminant Function, Random Forest, Support Vector Machine, etc. The package caret provides them.
