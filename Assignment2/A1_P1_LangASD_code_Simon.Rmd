---
title: "Portfolio 1"
author: "Simon Moeller Nielsen"
date: "25/09/2018"
output: html_document
---

# Assignment 1, Part 1: Language development in Autism Spectrum Disorder (ASD) - Brushing up your code skills

In this first part of the assignment we will brush up your programming skills, and make you familiar with the data sets you will be analysing for the next parts of the assignment.

In this first part of the assignment you will:
1) Create a Github (or gitlab) account and link it to your RStudio
2) Use small nifty lines of code to transform several data sets into just one. The final data set will contain only the variables that are needed for the analysis in the next parts of the assignment
3) Become familiar with the tidyverse package (especially the sub-packages stringr and dplyr), which you will find handy for later assignments.


## 0. First an introduction on the data

# Language development in Autism Spectrum Disorder (ASD)

Background: Autism Spectrum Disorder is often related to language impairment. However, this phenomenon has not been empirically traced in detail: i) relying on actual naturalistic language production, ii) over extended periods of time. We therefore videotaped circa 30 kids with ASD and circa 30 comparison kids (matched by linguistic performance at visit 1) for ca. 30 minutes of naturalistic interactions with a parent. We repeated the data collection 6 times per kid, with 4 months between each visit. We transcribed the data and counted: 
i) the amount of words that each kid uses in each video. Same for the parent.
ii) the amount of unique words that each kid uses in each video. Same for the parent.
iii) the amount of morphemes per utterance (Mean Length of Utterance) displayed by each child in each video. Same for the parent. 

## 1. Let's get started on GitHub

Follow the link to a Github tutorial: 
https://support.rstudio.com/hc/en-us/articles/200532077-Version-Control-with-Git-and-SVN

In the assignments you will be asked to upload your code on Github and the GitHub repositories will be part of the portfolio, therefore all students must make an account and link it to their RStudio (you'll thank us later for this!).

N.B. Create a GitHub repository for the Language Development in ASD set of assignments and link it to a project on your RStudio.

You may also use Gitlab instead of Github (Malte will explain in class)

## 2. Now let's take dirty dirty data sets and make them into a tidy one

If you're not in a project in Rstudio, make sure to set your working directory here.
If you created an rstudio project, then your working directory (the directory with your data and code for these assignments) is the project directory. You can always see which working directory is used with `getwd()`. Note that this may be different in the console than in the Rmd cells (don't ask me why).

```{r}
#Setting WD
setwd("C:/Users/slmoni/Documents/Uni/Experimental Methods III/R-stuff/Assignment1&2_LanguageASD")
```

Load the three data sets, after downloading them from dropbox and saving them in your working directory:
* Demographic data for the participants: https://www.dropbox.com/s/w15pou9wstgc8fe/demo_train.csv?dl=0
* Length of utterance data: https://www.dropbox.com/s/usyauqm37a76of6/LU_train.csv?dl=0
* Word data: https://www.dropbox.com/s/8ng1civpl2aux58/token_train.csv?dl=0

```{r}
# Loading data
demo<-read.csv("demo_train.csv",stringsAsFactors = F)
lu<-read.csv("LU_train.csv",stringsAsFactors = F)
token<-read.csv("token_train.csv",stringsAsFactors = F)
#Loading packages
library(dplyr)
library(plyr)
library(stringr)
library(tidyverse)
library(magrittr)
```

Explore the 3 datasets (e.g. visualize them, summarize them, etc.). You will see that the data is messy, since the psychologists collected the demographic data, a linguist analyzed the length of utterance in May 2014 and the same linguist analyzed the words several months later. In particular:
- the same variables might have different names (e.g. identifier of the child)
- the same variables might report the values in different ways (e.g. visit)
Welcome to real world of messy data :-)

Before being able to combine the data sets we need to make sure the relevant variables have the same names and the same kind of values.

So:

2a. Find a way to transform variable names.
Tip: Look into the package dplyr (part of tidyverse)
Tip: Or google "how to rename variables in R". 
Tip: Or look through the chapter on data transformation in R for data science (http://r4ds.had.co.nz).


```{r}
#Changing column names
colnames(demo)[1] <- "SUBJ"
colnames(demo)[2] <- "VISIT"
```

2b. Find a way to homogeneize the way "visit" is reported. If you look into the original data sets, you will see that in the LU data and the Token data, Visits are called "visit 1"" instead of just "1"" (which is the case in the demographic data set).
Tip: There is a package called stringr, which will be very handy for manipulating (text) strings also in furture assignments. We will return to this package later, but for now use the str_extract () to extract only the number from the variable Visit in each data set.

```{r}
# Removing the dot in Visit
lu$VISIT<-str_extract (lu$VISIT,"[0-9]+")
token$VISIT<-str_extract (token$VISIT,"[0-9]+")
```

2c. We also need to make a small adjustment to the content of the Child.ID coloumn in the demographic data. Within this column, names that are not abbreviations do not end with "." (i.e. Adam), which is the case in the other two data sets (i.e. Adam.). If The content of the two variables isn't identical the data sets will not be merged sufficiently.
We wish to remove the "." at the end of names in the LU data and the tokens data.

Tip: stringr is helpful again. Look up str_replace_all
Tip: You can either have one line of code for each child name that is to be changed (easier, more typing) or specify the pattern that you want to match (more complicated: look up "regular expressions", but less typing)

Tip: You will have to do identical work for both data sets, so to save time on the copy/paste use the cmd+f/ctrl+f function. Add the data frame name (e.g. LU_data) in the first box, and the data frame name (e.g. Tokens_data) you wish to change it to in the other box, and press replace. Or create a function that takes the data set and does the transformation. Then call the function on both data sets.


```{r}
#Removing the dot form the end of names unless the name was an acronym
for (row in 1:nrow(lu)) {
  dot <- str_count(lu[row,"SUBJ"], '[.]')
  if (dot == 1) {
  lu[row,"SUBJ"]<-str_replace(lu[row,"SUBJ"],"([.])", "")}
}

for (row in 1:nrow(token)) {
  dot <- str_count(token[row,"SUBJ"], '[.]')
  if (dot == 1) {
  token[row,"SUBJ"]<-str_replace(token[row,"SUBJ"],"([.])", "")}
}
```

2d. Now that the nitty gritty details of the different data sets are fixed, we want to make a subset of each data set only containig the variables that we wish to use in the final data set.
For this we use the tidyverse package dplyr, which contains the function select(). 

The variables we need are: Child.ID, Visit, Ethnicity, Diagnosis, Gender, Age, ADOS,  MullenRaw, ExpressiveLangRaw, MOT_MLU, MOT_LUstd, CHI_MLU, CHI_LUstd, types_MOT, types_CHI, tokens_MOT, tokens_CHI.

* ADOS indicates the severity of the autistic symptoms (the higher the score, the worse the symptoms)
* MLU stands for mean length of utterance
* types stands for unique words (e.g. even if "doggie" is used 100 times it only counts for 1)
* tokens stands for overall amount of words (if "doggie" is used 100 times it counts for 100) 
* MullenRaw indicates non verbal IQ
* ExpressiveLangRaw indicates verbal IQ

It would be smart to rename the last two into something you can remember (i.e. nonVerbalIQ, verbalIQ)

```{r}
#Making new datasets with only variables we are interrested in
demoNew<-select(demo, SUBJ, VISIT, Ethnicity, Diagnosis, Gender, Age, ADOS,  MullenRaw, ExpressiveLangRaw)
luNew<-select(lu,SUBJ, VISIT, MOT_MLU, MOT_LUstd, CHI_MLU, CHI_LUstd)
tokenNew<-select(token,SUBJ, VISIT, types_MOT, types_CHI, tokens_MOT, tokens_CHI)
```

2e. Finally we are ready to merge all the data sets into just one. 
Tip: Look up "joins" in R for data science, or google "How to merge datasets in R"
Tip: Joining / merging only works for two data frames at the time.

```{r}
# Merging all datasets into one
ADSHalf<-join(demoNew,luNew,by = c("SUBJ", "VISIT"))
ADS<-join(ADSHalf,tokenNew,by = c("SUBJ", "VISIT"))
# Changing column names
colnames(ADS)[which(names(ADS) == "MullenRaw")] <- "nonVerbalIQ"
colnames(ADS)[which(names(ADS) == "ExpressiveLangRaw")] <- "verbalIQ"
```

Are we done?
If you look at the data set now, you'll se a lot of NA's in the variables ADOS, nonVerbalIQ (MullenRaw) and verbalIQ (ExpressiveLangRaw). These measures were not taken at all visits. Additionally, we only want these measures for the first visit (Riccardo will explain why in class).
So let's make sure that we select only these variables as collected during the first visit for each child and repeat these values throughout all other visits.

* A way to get around this in R, is to make a subset of the data containing only the values we are interested in, i.e. the values at visit 1. We only want to keep the relevant variables in this data set, i.e the ones which values are to be repeated. Either the the subset() function or select() and filter() can be used here. Solve this issue with both functions to familiarize yourself with these useful functions. N.B. save the subset of the dataset as a new dataset, do not overwrite the old one.

* In order to merge these new variables to the final data set, they'll need new names. E.g change the ADOS variable to ADOS1.

* Once you've changed the names, the subset can be merged to the final data set, and the score at the 1st visit in each variable will be spread to all 6.

* Lastly, there are too many unneccesary variables in the data set by now. Use the select() to choose only the variables you want in the data (e.g. remove the old ADOS, verbal and nonVerbal IQ variables, so you will not get confused later on) and define the order of the variables. Hint: You want the child identifier, followed by diagnosis, followed by demographic, cognitive and clinical features, followed by indexes of linguistic performance (utterances lenghts, types and tokens of words).


```{r}
#Creating at subset of the data with only data form visit 1
ADS1<-subset(ADS, VISIT == 1)
#Not sure how to use select
ADS2<-filter(ADS, VISIT == 1)

# Changing colunm names to avoid them being lost in the merge
colnames(ADS1)[which(names(ADS1) == "ADOS")] <- "ADOS1"
colnames(ADS1)[which(names(ADS1) == "nonVerbalIQ")] <- "nonVerbalIQ1"
colnames(ADS1)[which(names(ADS1) == "verbalIQ")] <- "verbalIQ1"
# Merging the subset with the full dataset
ADSGOOD<-merge(ADS, ADS1, by.x="SUBJ", by.y="SUBJ")

#Setting columns to get rid of duplicates and giving them the correct names
ADSFinal<-select(ADSGOOD, SUBJ, VISIT.x, Diagnosis.x, Gender.x, Age.x, Ethnicity.x, ADOS1, nonVerbalIQ1, verbalIQ1, MOT_MLU.x, MOT_LUstd.x, CHI_MLU.x, CHI_LUstd.x, types_MOT.x, types_CHI.x, tokens_MOT.x, tokens_CHI.x)
names(ADSFinal) <- c("SUBJ","VISIT","Diagnosis", "Gender", "Age", "Ethnicity", "ADOS", "nonVerbalIQ", "verbalIQ", "MOT_MLU", "MOT_LUstd", "CHI_MLU", "CHI_LUstd", "types_MOT", "types_CHI", "tokens_MOT", "tokens_CHI")
```

Now, we are almost ready to start analysing the data. However, here are some additional finishing touches:

* in some experiments your participants must be anonymous. Therefore we wish to turn the CHILD.ID into numbers.

Tip: You will probably need to turn it into a factor first, then a number
Tip: google "R how to convert character to integer" or look up the as.??? functions

* In order to make it easier to work with this nice, clean dataset in the future, it is practical to make sure the variables have sensible values. E.g. right now gender is marked 1 and 2, but in two weeks you will not be able to remember, which gender were connected to which number, so change the values from 1 and 2 to F and M in the gender variable. For the same reason, you should also change the values of Diagnosis from A and B to ASD (autism spectrum disorder) and TD (typically developing). Tip: Try taking a look at ifelse(), or google "how to rename levels in R".

```{r}
# Changing variabel types
ADSFinal$SUBJ<-as.factor(ADSFinal$SUBJ)
ADSFinal$SUBJ<-as.integer(ADSFinal$SUBJ)
ADSFinal$Gender<-as.factor(ADSFinal$Gender)
ADSFinal$Diagnosis<-as.factor(ADSFinal$Diagnosis)
# Giving variables the right names 
levels(ADSFinal$Gender) <- c("M", "F")
levels(ADSFinal$Diagnosis) <- c("ASD", "TD")
```


Write the data set into a csv file. 

```{r}
# Saving the dataset
write.csv(ADSFinal, file = "ADSFinal_Simon.csv")
```


3) Now that we have a nice clean data set to use for the analysis next week, we shall play a bit around with it. The following exercises are not relevant for the analysis, but are here so you can get familiar with the functions within the tidyverse package.

Here's the link to a very helpful book, which explains each function:
http://r4ds.had.co.nz/index.html

USING FILTER
List all kids who:
1. have a mean length of utterance (across all visits) of more than 2.7 morphemes.
2. have a mean length of utterance of less than 1.5 morphemes at the first visit
3. have not completed all trials. Tip: Use pipes `%>%` to solve this

```{r}
#1
# Grouping by subject and getting the mean per subject
group_by(ADSFinal,SUBJ) %>% 
  dplyr::summarize(Mean = mean(CHI_MLU, na.rm=TRUE))%T>% 
  assign("mean1",.,envir = .GlobalEnv)
# Getting only the subjects with a mean over 2.7
filter(mean1, Mean == 2.7)

#2
# Getting only the subjects with a MLU of less then 1.5 at first visit
filter(ADSFinal, CHI_MLU < 1.5 & VISIT==1)

#3
# Getting the rows with NA is child MLU
group_by(ADSFinal,SUBJ) %>% 
  filter(is.na(CHI_MLU))%T>% 
  assign("isna",.,envir = .GlobalEnv)
# Finding unique subject which had NAs
unique(isna$SUBJ)
```


USING ARRANGE

1. Sort kids to find the kid who produced the most words on the 6th visit
2. Sort kids to find the kid who produced the least amount of words on the 1st visit.

```{r}
#1
# Making a dataset of tokens_CHI for visit 6
filter(ADSFinal,VISIT==6)%>% 
  arrange(tokens_CHI)%T>% 
  assign("arrange1",.,envir = .GlobalEnv)
# Finding subject with the highest number of tokens
arrange1[which.max(arrange1$tokens_CHI),]

#2
# Making a dataset of tokens_CHI for visit 1
filter(ADSFinal,VISIT==1)%>% 
  arrange(tokens_CHI)%T>% 
  assign("arrange2",.,envir = .GlobalEnv)
# Finding subject with the lowest number of tokens
arrange2[which.min(arrange2$tokens_CHI),]
```

USING SELECT

1. Make a subset of the data including only kids with ASD, mlu and word tokens
2. What happens if you include the name of a variable multiple times in a select() call?

```{r}
#1
#Making a subset of the data
ADSFinalASD<-select(ADSFinal, Diagnosis, MOT_MLU, CHI_MLU, tokens_MOT, tokens_CHI)
ADSFinalASD<-filter(ADSFinalASD, Diagnosis == "ASD")
#2
#Messing around with the select function
ADSFinalTest<-select(ADSFinal, Diagnosis, Diagnosis)
ADSFinalASD<-select(ADSFinal, Diagnosis)
#Nothing happens when the same variable is called multiple times
```


USING MUTATE, SUMMARISE and PIPES
1. Add a column to the data set that represents the mean number of words spoken during all visits.
2. Use the summarise function and pipes to add an column in the data set containing the mean amount of words produced by each trial across all visits. HINT: group by Child.ID 
3. The solution to task above enables us to assess the average amount of words produced by each child. Why don't we just use these average values to describe the language production of the children? What is the advantage of keeping all the data?

```{r}
#1
# Adding at column of to the dataset with the mean of token and saving it as a new dataframe
ADSFinalMutate<-mutate(ADSFinal, MeanTokenAll = mean(ADSFinal$tokens_CHI, na.rm=TRUE))
ADSFinalMutate

#2
# Finding the mean of tokens preduced by each child 
group_by(ADSFinal,SUBJ) %>% 
  dplyr::summarize(Mean = mean(tokens_CHI, na.rm=TRUE))%T>% 
  assign("meanToken",.,envir = .GlobalEnv)
# Merging those means with the full dataset
ADSMean<-merge(ADSFinal, meanToken, by.x="SUBJ", by.y="SUBJ")
#Not sure I understood this correctly, I can only see it as mean per child, don't know what would be consider a single trial in this experiment

#3
# Because we are interested in the development of there language over time
```
